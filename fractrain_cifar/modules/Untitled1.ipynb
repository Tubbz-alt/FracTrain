{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd.function import InplaceFunction, Function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input = torch.Tensor([2.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input.clamp_(0, 5).round_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(20,10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1143, 0.0202, 0.0626, 0.0347, 0.0578, 0.0032, 0.0907, 0.0410, 0.0370,\n",
       "         0.0522, 0.0041, 0.1042, 0.0102, 0.0070, 0.0128, 0.0366, 0.0298, 0.0051,\n",
       "         0.0244, 0.0171]),\n",
       " tensor([13, 14,  3,  8,  6,  2,  8, 20,  8,  6, 17, 17, 19,  6, 15, 19, 26, 25,\n",
       "         29, 18]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(a.size(0),-1).min(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = a.view(a.shape[0]//20,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 600])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0032)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min(-1)[0].mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = nn.Conv2d(3, 5, kernel_size=3, stride=1,\n",
    "                     padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 3, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer.weight[0,:,:,:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformQuantize(InplaceFunction):\n",
    "\n",
    "    @classmethod\n",
    "    def forward(cls, ctx, input, num_bits=8, min_value=None, max_value=None,\n",
    "                stochastic=False, inplace=False, enforce_true_zero=False, num_chunks=None, out_half=False):\n",
    "\n",
    "        num_chunks = num_chunks = input.shape[\n",
    "            0] if num_chunks is None else num_chunks\n",
    "        if min_value is None or max_value is None:\n",
    "            B = input.shape[0]\n",
    "            y = input.view(B // num_chunks, -1)\n",
    "        if min_value is None:\n",
    "            min_value = y.min(-1)[0].mean(-1)  # C\n",
    "            #min_value = float(input.view(input.size(0), -1).min(-1)[0].mean())\n",
    "        if max_value is None:\n",
    "            #max_value = float(input.view(input.size(0), -1).max(-1)[0].mean())\n",
    "            max_value = y.max(-1)[0].mean(-1)  # C\n",
    "        ctx.inplace = inplace\n",
    "        ctx.num_bits = num_bits\n",
    "        ctx.min_value = min_value\n",
    "        ctx.max_value = max_value\n",
    "        ctx.stochastic = stochastic\n",
    "\n",
    "        if ctx.inplace:\n",
    "            ctx.mark_dirty(input)\n",
    "            output = input\n",
    "        else:\n",
    "            output = input.clone()\n",
    "\n",
    "        qmin = 0.\n",
    "        qmax = 2.**num_bits - 1.\n",
    "        #import pdb; pdb.set_trace()\n",
    "        scale = (max_value - min_value) / (qmax - qmin)\n",
    "\n",
    "        scale = max(scale, 1e-8)\n",
    "\n",
    "        if enforce_true_zero:\n",
    "            initial_zero_point = qmin - min_value / scale\n",
    "            zero_point = 0.\n",
    "            # make zero exactly represented\n",
    "            if initial_zero_point < qmin:\n",
    "                zero_point = qmin\n",
    "            elif initial_zero_point > qmax:\n",
    "                zero_point = qmax\n",
    "            else:\n",
    "                zero_point = initial_zero_point\n",
    "            zero_point = int(zero_point)\n",
    "            output.div_(scale).add_(zero_point)\n",
    "        else:\n",
    "            output.add_(-min_value).div_(scale).add_(qmin)\n",
    "\n",
    "        if ctx.stochastic:\n",
    "            noise = output.new(output.shape).uniform_(-0.5, 0.5)\n",
    "            output.add_(noise)\n",
    "        output.clamp_(qmin, qmax).round_()  # quantize\n",
    "\n",
    "        if enforce_true_zero:\n",
    "            output.add_(-zero_point).mul_(scale)  # dequantize\n",
    "        else:\n",
    "            output.add_(-qmin).mul_(scale).add_(min_value)  # dequantize\n",
    "        if out_half and num_bits <= 16:\n",
    "            output = output.half()\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # straight-through estimator\n",
    "        grad_input = grad_output\n",
    "        return grad_input, None, None, None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Variable(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = UniformQuantize().apply(a,8,None,None,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1503, 0.8787, 0.4591, 0.2252, 0.3175],\n",
       "        [0.3072, 0.3202, 0.7554, 0.4125, 0.8316],\n",
       "        [0.9673, 0.9366, 0.4022, 0.6118, 0.6386],\n",
       "        [0.4410, 0.4244, 0.5805, 0.5696, 0.7735]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = conv_layer.weight[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = conv_layer.weight[1,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([w.unsqueeze(0)]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
